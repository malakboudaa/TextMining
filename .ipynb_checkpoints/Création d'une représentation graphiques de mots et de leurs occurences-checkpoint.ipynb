{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1434d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ff5a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc1 = \"La collecte de ces données a plusieurs objectifs. Elle permet de constituer en temps réel une cohorte de patients infectés, qui inclut aujourd’hui plus de 500 000 patients et qui est devenue une base de données de référence dans le monde\"\n",
    "\n",
    "Doc2 = \"Cette base de données alimente près de 60 travaux de recherche des Hôpitaux de Paris portant sur les caractéristiques cliniques de la maladie, sur l’impact de certains médicaments ou encore sur l’étude des facteurs aggravants\"\n",
    "\n",
    "Doc3 = \"En y injectant de l’intelligence artificielle, l’AP-HP et ses partenaires mènent également des études de prédiction et testent virtuellement des solutions capables de stopper le virus. Par exemple, ils développent des algorithmes d’apprentissage profond (deep learning) utilisant les données de radiographie et de scanner pour créer des outils fiables de prédiction de formes sévères de Covid-19\"\n",
    "\n",
    "Doc4 = \"L’exploitation de ces données permet également d’établir des statistiques et des visualisations, et de fournir des informations réutilisables. Elles sont mises à disposition des équipes d’encadrement des unités de soin sur un portail dédié pour les aider à mieux comprendre le virus, ses évolutions et sa diffusion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3d968a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(\"\\d+|\\.|,|Md$|%|:$|\\)|\\(|\\n\",'',Doc1).lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2879dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au',\n",
       " 'aux',\n",
       " 'avec',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'et',\n",
       " 'eux',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'je',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'même',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'ses',\n",
       " 'son',\n",
       " 'sur',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'c',\n",
       " 'd',\n",
       " 'j',\n",
       " 'l',\n",
       " 'à',\n",
       " 'm',\n",
       " 'n',\n",
       " 's',\n",
       " 't',\n",
       " 'y',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étants',\n",
       " 'étantes',\n",
       " 'suis',\n",
       " 'es',\n",
       " 'est',\n",
       " 'sommes',\n",
       " 'êtes',\n",
       " 'sont',\n",
       " 'serai',\n",
       " 'seras',\n",
       " 'sera',\n",
       " 'serons',\n",
       " 'serez',\n",
       " 'seront',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'serions',\n",
       " 'seriez',\n",
       " 'seraient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étions',\n",
       " 'étiez',\n",
       " 'étaient',\n",
       " 'fus',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fûtes',\n",
       " 'furent',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'soyons',\n",
       " 'soyez',\n",
       " 'soient',\n",
       " 'fusse',\n",
       " 'fusses',\n",
       " 'fût',\n",
       " 'fussions',\n",
       " 'fussiez',\n",
       " 'fussent',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eus',\n",
       " 'ai',\n",
       " 'as',\n",
       " 'avons',\n",
       " 'avez',\n",
       " 'ont',\n",
       " 'aurai',\n",
       " 'auras',\n",
       " 'aura',\n",
       " 'aurons',\n",
       " 'aurez',\n",
       " 'auront',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'aurions',\n",
       " 'auriez',\n",
       " 'auraient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avions',\n",
       " 'aviez',\n",
       " 'avaient',\n",
       " 'eut',\n",
       " 'eûmes',\n",
       " 'eûtes',\n",
       " 'eurent',\n",
       " 'aie',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'ayons',\n",
       " 'ayez',\n",
       " 'aient',\n",
       " 'eusse',\n",
       " 'eusses',\n",
       " 'eût',\n",
       " 'eussions',\n",
       " 'eussiez',\n",
       " 'eussent']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e44ccd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'la collecte de ces données a plusieurs objectifs elle permet de constituer en temps réel une cohorte de patients infectés qui inclut aujourd’hui plus de   patients et qui est devenue une base de données de référence dans le monde'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(Doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d467b0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['collecte', 'données', 'a', 'plusieurs', 'objectifs', 'permet', 'constituer', 'temps', 'réel', 'cohorte', 'patients', 'infectés', 'inclut', 'aujourd', '’', 'hui', 'plus', 'patients', 'devenue', 'base', 'données', 'référence', 'monde']\n"
     ]
    }
   ],
   "source": [
    "#recuperer les stopwords\n",
    "StopWord = set(stopwords.words('french'))\n",
    "\n",
    "#wordtokenize (tokenisation) est utilisée pour diviser le text \n",
    "#clean_text pour supprimer tt les caractere dont on a pas besoins du text (défini la fonction en haut) \n",
    "DocList = word_tokenize(clean_text(Doc1).lower())\n",
    "DocFil = [w for w in DocList if not w in StopWord]\n",
    "print (DocFil)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e299151",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
